---
title: Using conventional alpha values for hypothesis tests obscures the meaning
  of "statistical significance"
author: Yeng Miller-Chang
date: '2024-03-08'
slug: alpha-value-meaning
categories: []
tags:
  - statistics
subtitle: ''
summary: ''
authors: []
lastmod: '2024-03-08T23:09:34-06:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
---

<script src="{{< blogdown/postref >}}index.en_files/header-attrs/header-attrs.js"></script>


<p><em>Views and opinions expressed are solely my own.</em></p>
<p>I once had a conversation with someone who wanted help designing an A/B test for a website. The design was more or less what one would have for a conventional two-sample proportions <span class="math inline">\(Z\)</span>-test: users would be assigned randomly, by IP address, to one of two versions of a website. The goal was to see which of the two versions of this website would lead to a higher proportion of users clicking ads.</p>
<p>This analyst set <span class="math inline">\(\alpha = 0.05\)</span>, simulated fictitious data, and executed their hypothesis test on these data. Upon executing this procedure some large number of times, they pinged me again, and said to me, “Yeng, something’s wrong with this test.” I reviewed their R code: found nothing wrong with the computations, and I asked them to elaborate. Then they told me what was actually wrong:</p>
<p><em>In digital marketing, a 1% increase in ad clicks is huge.</em></p>
<p>Yes, I know that is the case, I told them.</p>
<p><em>So why is my hypothesis test not labeling such a test as “significant”?</em>, they asked.</p>
<p>I told them: it’s your <span class="math inline">\(\alpha\)</span> value.</p>
<p><em>But I was told to always set <span class="math inline">\(\alpha = 0.05\)</span>,</em> they told me.</p>
<p>Sure - but by setting your <span class="math inline">\(\alpha\)</span> value, you are in fact making a judgement call on what is deemed “statistically significant,” I told them.</p>
<hr />
<p>I don’t think I was able to convince them otherwise after that discussion. The convention of setting <span class="math inline">\(\alpha = 0.05\)</span> seemed to have been ingrained in the way they executed their hypothesis tests, but just like any rule of thumb, <em>one must know why such rules of thumbs exist</em> and therefore <em>when such rules of thumb may fail</em>. In this post, I am here to make one point:</p>
<div id="with-each-alpha-value-there-is-at-least-one-corresponding-value-measured-in-units-of-the-existing-data-which-is-deemed-the-boundary-for-significance." class="section level2">
<h2>With each alpha value, there is at least one corresponding value measured in units of the existing data which is deemed the boundary for “significance.”</h2>
<p>Let’s suppose, for example, that in this scenario, we have two versions of a website as described above and we had 1500 people each who saw both websites. Suppose in the first version website that 5% (or 75 people) of the users clicked on an ad. If we deem a 1% increase as being “statistically significant,” we can find an <span class="math inline">\(\alpha\)</span> value that corresponds to this. Here’s how: we assume we have a 1% increase in the number of people (or 90 people) who have clicked in an ad in the second group compared to the first group. The test statistic is obtained by
<span class="math display">\[\begin{equation}
z = \dfrac{(0.05 + 0.01) - 0.05}{\sqrt{p(1-p)\left(\dfrac{2}{1500} \right)}}
\end{equation}\]</span>
where
<span class="math display">\[\begin{equation}
p = \dfrac{75+90}{2(1500)} = \dfrac{165}{3000}\text{.}
\end{equation}\]</span>
Suppose <span class="math inline">\(Z\)</span> is of the standard normal distribution, with mean <span class="math inline">\(0\)</span> and variance <span class="math inline">\(1\)</span>. Then since this is a right-tailed test, any value <span class="math inline">\(\alpha\)</span> for which
<span class="math display">\[\begin{equation}
\mathbb{P}(Z \geq z) \leq \alpha
\end{equation}\]</span>
will lead to “statistical significance.” The probability above can easily be calculated:</p>
<pre class="r"><code>z_num &lt;- (0.05 + 0.01) - 0.05
p &lt;- (75 + 90)/(2 * 1500)
z_denom &lt;- sqrt(p * (1-p) * (2/1500))
print(1 - pnorm(z_num/z_denom))</code></pre>
<pre><code>## [1] 0.1148271</code></pre>
<p>So as you see above: this defies convention. For this particular use case, assuming this analyst had similar numbers to what I had above, an <span class="math inline">\(\alpha \geq 0.114\)</span> would suffice for this problem. This problem illustrates that blindly setting <span class="math inline">\(\alpha\)</span> to conventional values like <span class="math inline">\(0.05\)</span> or <span class="math inline">\(0.01\)</span> <em>when one already has in mind what is deemed “significant”</em> does not make sense.</p>
</div>
<div id="the-inverse-problem" class="section level2">
<h2>The inverse problem</h2>
<p>However, the inverse problem is true too: when one sets an <span class="math inline">\(\alpha\)</span> value, one can express what is deemed “statistically significant” in terms of units of the original statistic. Suppose we set <span class="math inline">\(\alpha = 0.05\)</span>. Suppose we also know that <span class="math inline">\(75\)</span> people clicked on the ad in the first version and <span class="math inline">\(n\)</span> people clicked on the ad in the second version. Using the same logic as above, this would be the same as finding <span class="math inline">\(n\)</span> such that
<span class="math display">\[\begin{equation}
\mathbb{P}(Z \geq z) \leq \alpha = 0.05
\end{equation}\]</span>
<span class="math display">\[\begin{equation}
z = \dfrac{\dfrac{n}{1500} - 0.05}{\sqrt{p(1-p)\left(\dfrac{2}{1500} \right)}}
\end{equation}\]</span>
where
<span class="math display">\[\begin{equation}
p = \dfrac{75+n}{2(1500)} = \dfrac{n+75}{3000}\text{.}
\end{equation}\]</span>
Such a corresponding <span class="math inline">\(z\)</span>, at minimum, must be equal to</p>
<pre class="r"><code>qnorm(0.95)</code></pre>
<pre><code>## [1] 1.644854</code></pre>
<p>so we solve
<span class="math display">\[\begin{equation}
\dfrac{\dfrac{n}{1500} - 0.05}{\sqrt{\dfrac{n+75}{3000}\left(1-\dfrac{n+75}{3000}\right)\left(\dfrac{2}{1500} \right)}} = 1.644854\text{.}
\end{equation}\]</span>
Using something like <a href="https://www.wolframalpha.com/input?i=solve+%28%28n%2F1500%29-0.05%29%2Fsqrt%28%28n%2B75%29%2F3000+*+%281+-+%28n%2B75%29%2F3000%29+*+%282%2F1500%29%29+%3D+1.644854">Wolfram Alpha</a>, one obtains <span class="math inline">\(n = 96\)</span>. Thus, in the situation outlined above, the analyst should have recognized by setting <span class="math inline">\(\alpha = 0.05\)</span>, they were aiming for a <span class="math inline">\(\dfrac{96}{1500}\)</span> being marked as “statistically significant,” or an increase of<br />
<span class="math display">\[\begin{equation}
\dfrac{96}{1500} - \dfrac{75}{1500} = 0.014
\end{equation}\]</span>
which means that at a <span class="math inline">\(1.4\%\)</span> increase or higher, the result would have been “statistically significant” - which is larger than what the analyst intended in this case for being marked as “significant.”</p>
<p>The principles outlined here can be extended to virtually any hypothesis test.</p>
</div>
<div id="conclusion" class="section level2">
<h2>Conclusion</h2>
<p>Please do not blindly set your <span class="math inline">\(\alpha\)</span> values because of convention. Know that every time an <span class="math inline">\(\alpha\)</span> value is set, you are in fact making a decision in terms of the units of your original data (percentages in this case) what is deemed “statistically significant.” This is also true with <span class="math inline">\(p\)</span>-values, too: each <span class="math inline">\(p\)</span>-value you calculate can be expressed in the original units as well.</p>
<p>I hope eventually we can move on from using <span class="math inline">\(\alpha\)</span> values and <span class="math inline">\(p\)</span>-values as indicators for statistical significance, and simply express cutoffs in the original units of the data to be more explicit about what we mean when we talk about “statistical significance.”</p>
</div>
